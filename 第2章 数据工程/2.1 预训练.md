
### 2.1.1 数据处理流程
在收集了大量的文本数据后，必须对数据进行预处理，以构建预训练预料，特别是去除噪声、冗余、不相关
和潜在的有毒数据。
Raw Corpus -> Quality Filtering -> De-duplication -> Privacy Reduction -> Tokenization
（0）原始数据
数据要求 高质量 大规模 多样性
预训练数据对LLM的影响:1)来源的混合，通过对不同来源的混合文本数据进行预训练，LLM可以获得广泛的知识范围，并可能表现出强大的概括能力。2）预训练的数据量，Chinchila进一步
证明了在给定计算预算下，以相等的比例增加模型大小和数据大小可以导致一个更有计算效率的模型（20：1）
3）预训练数据的质量，现有的工作表明，在低质量的语料库上进行预训练，如噪声、有毒和重复的数据，可能会损害模型的性能。
（1）质量过滤
从收集到的语料库中去除低质量的数据，现通常采用两种方法：（1）基于分类器；（2）基于启发式
**分类器方法**是基于高质量的文本训练一个选择分类器，并利用它来识别和过滤低质量的数据。基于分类器的方法可能会导致无意中删除方言、口语和社会选择语言中高质量文本，
这可能会导致预训练语料库的偏差，并减少语料库的多样性。
**启发式方法**通过一套人工设计的规则来消除低质量的文本，包括基于语言的过滤（如果一个LLM主要用于某些语言的任务，其他语言的文本可以被过滤掉）。基于度量的过滤（关于
生成的文本的评估指标，例如困惑度，可以用来检测和删除不自然的句子）。基于统计学的过滤（语料库的统计特征，如标点符号分布、符号与单词的比率和句子长度，可以用来衡量文本
质量并过滤低质量的数据）。基于关键词的过滤（基于特定的关键词集，文本中的噪音或不常用的元素，如HTML标签、超链接、模板和攻击性的词语，可以被识别和删除。

（2）去重
现有的工作发现，语料库中的重复数据会降低语言模型的多样性，这可能会导致训练过程的变得不稳定，从而影响模型的性能。
因此，有必要对预训练语料库进行去重。特别是，去重可以在不同的粒度上进行，包括句子级、文档级和数据集去重。首先，应删除含有重复词和短语的低质量句子，因为它们可能在语言建模
中引入重复模式；在文档层面，现有的研究大多依靠文档之间表面特征的重叠率（如单词和n-grams的重叠）来检测和删除包含类似内容的重复文档；此外为了避免数据集的污染问题，防止
训练集和评估集重叠极为关键，通过从训练集中删除可能的重复文本。
（3）隐私重构
大多数预训练的文本数据都是从网络来源获得，包括涉及敏感或个人信息的用户生成的内容，这可能会增加隐私侵犯的风险，因此有必要将个人身份信息从预训练语料库中移除。
一个直接而有效的方法是采用基于规则的方法，如关键词发现，来检测删除个人身份信息。
（4）分词
Tokenization也是数据预处理的一个关键步骤，它的目的是将原始文本分割成单个标记的序列，作为LLM的输入。
### 2.1.2 数据清洗类别
(1) 标题处理

(2) 表格处理
table2text
(3) 图片处理

(4) 超链接处理


### 2.1.3 数据质量评估
when less is more: Investigating Data Prunting for Pretraining LLMs at Scale 探索了三种不同的启发式方法进行质量评估，包括困惑度
(perplexity)、错误L2范数（ErrorL2-Norm)和记忆化（memeorization）。  
--基于困惑度的质量评估，perplexity衡量的是特定文本在特定语言模型基础上的可能性。对于
--基于错误L2范数（ErrorL2-Norm）的质量评估
--基于记忆化（memorization）的质量评估