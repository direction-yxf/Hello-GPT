&emsp;&emsp;在收集了大量的文本数据后，必须对数据进行预处理，以构建预训练预料，特别是去除噪声、冗余、不相关和潜在的有毒数据。
### 2.1.1 数据处理流程
&emsp;&emsp;预训练数据的清洗流程包含4个步骤：Raw Corpus -> Quality Filtering -> De-duplication -> Privacy Reduction -> Tokenization。
**（0）原始数据**  
&emsp;&emsp;原始数据要求高质量、大规模和多样性。其中**高质量**高质量数据集能够提高模型精度与可解释性，并且减少收敛到最优解的时间，减少训练时长；高质量数据的选择依据是信源权威可靠、内容价值观对齐、专业领域知识，不会选择不入流的站点数据；高质量的数据具有规范性、完整性、准确性、一致性和时效性；
**大规模**表示预训练的数据量越多，大模型的拟合能力就越强，效果就会越来越好，如果数据规模太小的话，模型学的东西不会多，记得也不够深刻。**多样性**表示数据丰富性能够提高大模型的泛化能力。  
&emsp;&emsp;在低质量的语料库上进行预训练，如噪声、有毒和重复的数据，可能会损害模型的性能。  
**（1）质量过滤**  
&emsp;&emsp;从收集到的语料库中去除低质量的数据，现通常采用两种方法：（1）基于分类器；（2）基于启发式：
**分类器方法**是基于高质量的文本训练一个选择分类器，并利用它来识别和过滤低质量的数据。基于分类器的方法可能会导致无意中删除方言、口语和社会选择语言中高质量文本，
这可能会导致预训练语料库的偏差，并减少语料库的多样性。  
**启发式方法**通过一套人工设计的规则来消除低质量的文本，包括基于语言的过滤（如果一个LLM主要用于某些语言的任务，其他语言的文本可以被过滤掉）。基于度量的过滤（关于
生成的文本的评估指标，例如困惑度，可以用来检测和删除不自然的句子）。基于统计学的过滤（语料库的统计特征，如标点符号分布、符号与单词的比率和句子长度，可以用来衡量文本
质量并过滤低质量的数据）。基于关键词的过滤（基于特定的关键词集，文本中的噪音或不常用的元素，如HTML标签、超链接、模板和攻击性的词语，可以被识别和删除。  
**（2）去重**  
&emsp;&emsp;现有的工作发现，语料库中的重复数据会降低语言模型的多样性，这可能会导致训练过程的变得不稳定，从而影响模型的性能。因此，有必要对预训练语料库进行去重。特别是，去重可以在不同的粒度上进行，包括句子级、文档级和数据集去重。首先，应删除含有重复词和短语的低质量句子，因为它们可能在语言建模
中引入重复模式；在文档层面，现有的研究大多依靠文档之间表面特征的重叠率（如单词和n-grams的重叠）来检测和删除包含类似内容的重复文档；此外为了避免数据集的污染问题，防止
训练集和评估集重叠极为关键，通过从训练集中删除可能的重复文本。  
**（3）隐私重构**  
&emsp;&emsp;大多数预训练的文本数据都是从网络来源获得，包括涉及敏感或个人信息的用户生成的内容，这可能会增加隐私侵犯的风险，因此有必要将个人身份信息从预训练语料库中移除。
一个直接而有效的方法是采用基于规则的方法，如关键词发现，来检测删除个人身份信息。  
**（4）分词**  
&emsp;&emsp;Tokenization也是数据预处理的一个关键步骤，它的目的是将原始文本分割成单个标记的序列，作为LLM的输入。在大模型的训练和预测都需要借助词表来对句子进行表示。  
-BPE（Byte Pair Encoding），由Sennrich等人2015年引入到NLP领域并很快得到推广，该算法简单有效，准备足够大的训练语料，并确定期望的Subword词表大小；将单词拆分成最小单元，比如英文中的字母表；在语料上统计单词内相邻单元对的频数，选取频数最高的单元对合并成新的subword单元；重复上一步指导达到词表大小。  
-WordPiece，与BPE算法类似，wordpiece算法也是从词表中选择两个字词合并成新的子词，区别在于BPE选择频数最高的相邻子词合并，而wordpiece选择能够提升语言模型概率最大的相邻子词加入词表。  

### 2.1.2 数据清洗类别
(1) 标题处理  
标题：正文  
(2) 表格处理  
table2text大模型解析，或者其他解析工具
(3) 图片处理  
暂时删掉  
(4) 超链接处理  
关键词过滤


### 2.1.3 数据质量评估
when less is more: Investigating Data Prunting for Pretraining LLMs at Scale 探索了三种不同的启发式方法进行质量评估，包括困惑度
(perplexity)、错误L2范数（ErrorL2-Norm)和记忆化（memeorization）。  
--基于困惑度的质量评估，perplexity衡量的是特定文本在特定语言模型基础上的可能性。困惑度得分越低，说明模型赋予文本的概率越高。  
--基于错误L2范数（ErrorL2-Norm）的质量评估，用于确定哪些样本对学习是重要的，它利用模型的早期学习信号来衡量每个样本的重要性。EL2N分数较低的例子通常是在模型在早期训练阶段学习得到，这可能是因为他们相对较容易。
--基于记忆化（memorization）的质量评估。为了确保记忆分数的适用性，使用了保证看过完整训练集的参考模型。记忆分数越高，说明模型逐字再现的文本越多。  
1、删除简单实例可提高性能  
2、简单剪枝方法指标优于更复杂的方法  
