### 5.0.1 测评工程
***（1）大模型时代，为什么需要新的测评基准***  
-需要开放域多任务下综合测评LLM。类ChatGPT大模型在多个领域的多个任务中都表现优秀，如果单独用过去某一领域的某一具体任务评估大模型的性能好坏，是不客观且不去免得，因此传统的单一数据集不再使用当前LLM的测评。  
-传统数据集都已被模型拿去训练。互联网上目前所有的NLP领域公开测评数据集，几乎都会被ChatGPT等大型语言模型在预训练阶段中使用，用于自监督学习或微调，如QA数据集中问题的答案已经在模型训练阶段被模型学习过，因此传统的测评数据集已不再具有测评意义，不再适用与当前LLM的微调。  
-需要标准化测评”去伪存真“。当前大模型百花齐放，但质量参差不齐，媒体宣传往往夸大其词，自说自话，业界需要一个公平公正公开的大模型测评基准和平台，展示不同模型的优缺点，给使用大模型的组织或个人提供高效的技术选型。  
-促进大模型技术发展。对于大模型研究人员，将各类大模型的效果对比，可反映出背后不同的技术路线、技术方法的有效性对比，提供了非常好的参考意义。不同大模型的相互参考、借鉴，避免重复实验带来的资源浪费，有助于整个大模型生态圈的良性高效发展，主力未来大模型的持续快速发展。  
***（2）当前LLM测评基准和平台现状***  
-暂未统一。目前业界和学界提出的大模型测评基准非常多，还没有一个业界公认的基准，各个公司或学术组织各自为战。  
-各有优劣。目前各类测评方法各有优劣，想构建全面且准确的测评LLM能力的平台，并达成业界共识，具有非常大的难度。  
-缺少共识。能力边界当前没有统一清晰的定义，如代码能力、写作能力、多轮能力等，一共需要测试哪些能力？当前业界缺少共识，对能力的划分各不相同，且覆盖性和正交性也各不相同。  

***（3）测评方法论***  
&emsp;&emsp;2023年8月，A Survey on  Evaluation of Large Language Models 综述一共调研了两百余篇文献，以评测对象（what to evaluate）、评测领域（where
to evaluate）、评测方法（how to evaluate）和目前的评估挑战等几大方面对大模型评估进行了详细的总结和梳理。我们的目标是增强对大模型当前状态的理解，阐明他们的优势和局限性，并为其未来发展提供其意见。  

1、评估什么？  
-自然语言处理：包括自然语言理解、推理、自然语言生成和多语言任务
-鲁棒性、伦理、偏见和真实性
-医学应用：包括医学问答、医学考试、医学教育和医学助手
-社会科学
-自然科学与工程：包括数学、通用科学与工程
-代理应用：使用LLMs作为代理
-其他应用  
2、如何评估？  
&emsp;&emsp;评测方法可以分为：自动评估（auto evaluation）和人工评估（human evaluation）。分类标准基于结果是否自动计算，如果可以自动计算，那就是自动评估，
否则，就是人工评估。  
**自动评估**。优势：速度快：迅速得到评估结果，特别是大量数据；客观性：基于预定义的指标和算法，减少偏见；可重复性：相同数据和模型得到相同的结果；成本效益：
比人工评估更经济。劣势：可能不准确：对复杂或非标准任务；缺乏深度：无法捕捉细微的质量差异；依赖标准指标：可能不适用所有任务。  
-指标测评：Accuracy、BLEU、ROUGE、BERTScore、困惑度、speed of grokking等。  
-benchmark测评：代表性的测评基准有谷歌的BIG-bench、斯坦福HELM、清华和上交的C-Eval、HuggingFace的Open LLM Leaderboard等，主要通过构建多任务混合的数据集测评模型。  
-大模型测评：代表性的测评方法有北大和微软联合的PandaLM等，通过训练一个可以给内容打分的裁判大模型或者通过调用OpenAI的GPT-4的API接口作为裁判模型，来给其他模型打分和做出评价。  
**人工评估**。优势：准确性：理解和评估模型输出的复杂性；灵活性：应对非标准任务和场景；深度：提供详细和有深度的反馈。劣势：成本高：需要雇佣评估员；时间消耗：
比自动评估耗时；可能存在偏见：不同评估员的不同观点；不稳定性：文化和个体差异导致的变异性。  
-人工裁判的测评：代表性的平台是UCB的Chatbot Arena，核心思想是通过大模型两两PK，人当裁判，采用竞技比赛Elo评分机制。  
